---
title: "Parametric Significance Tests"
---

::: {custom-style="TextBoxStyle"}
Parametric significance tests assess whether model parameters contribute meaningfully to explaining the variability in data. These tests are crucial for determining whether observed differences are statistically valid and help guide decisions on which factors should be included in further analysis.

The choice of test depends on the type of data, the research question, the dataset’s structure, and the assumptions underlying the statistical model. These tests are typically used when the data is assumed to follow a certain distribution (e.g., normal distribution) and often involve comparing means or evaluating relationships between variables.
:::

## Simpler Methods for Comparing Group Means

t-tests and ANOVA are commonly used in trial data analysis where the predictor variables are categorical, and the response variable is continuous. These tests compare the mean of each group’s response data to identify whether there are significant differences between groups. Both tests operate by comparing observed data with a fitted model and assume that the residuals (the differences between each observed value and the predicted group mean) are approximately normally distributed. This assumption is crucial because the reliability of the tests depends on the normality of the residuals, which is influenced by the underlying distribution of the raw data. If the residuals deviate significantly from normality, the results may be misleading.

**Fitting a Linear Model:** When fitting a linear model using ANOVA or a t-test, the model generates predicted values for each observation, based on the entire dataset and accounting for the effects of predictor variables (e.g., treatments or environmental conditions). These predicted values represent the expected value for each group, reflecting both overall trends and specific conditions for each group. By incorporating these group-level patterns, the model helps smooth out irregularities in the residuals, making them more likely to follow a normal distribution—even when the raw data itself does not. This smoothing effect helps ensure that the assumption of normality is more likely to hold after fitting the model.

While ANOVA and t-tests can be applied to discrete data such as weed counts, emergence counts, or panicle counts if the data follows a relatively normal distribution, these tests are generally not the best choice for count data, even when the data is normally distributed. Count data often follows non-normal distributions, such as Poisson or negative binomial, which violate the normality assumption required by these tests. In such cases, generalized linear models (GLMs) are a more suitable alternative, as they can model the specific distributional properties of count data (e.g., Poisson or negative binomial), leading to more reliable and accurate results.

Challenges in Agricultural Research: While t-tests and ANOVA are effective in controlled experimental designs with carefully managed conditions, they are less suitable for on-farm experiments, where environmental factors are often uncontrollable and vary significantly. Agricultural data is typically more complex, involving repeated measurements, hierarchical structures (e.g., fields, plots, and individual plants), and interactions between treatment and environmental variables. These complexities introduce correlations between observations or non-independence within groups, which t-tests and ANOVA are not designed to handle. To account for these factors and ensure valid conclusions, more advanced statistical methods, such as mixed-effects models, are often required.

t-tests and ANOVA are used in the analysis of trial data whwere the predictor variables are categorical and the response data is contiuous and function by comparing the means of different groups to identify significant differences between them. Both tests operate by comparing the observed data against a fitted model, and they assume that the residuals (the differences between the observed values and the model's predicted values) are normally distributed. This assumption is important because it underpins the reliability of these tests. If the residuals deviate significantly from normality, the results of these tests may be misleading.

The process of fitting a linear model, whether using ANOVA or a t-test, can help mitigate the impact of skewness or extreme values in the raw data. These tests essentially create a model that predicts the group means based on the observed data (is this all the groups together or group by group??), helping to smooth out any irregularities in the data (is this because it's including the other predictors effects in the predicted value of each group??. In doing so, the residuals — the differences between each observed value and its group’s predicted mean — may become more normally distributed, even when the raw data itself does not follow a normal distribution. This process can help to approximate normality in the residuals, which is why the assumptions of normality are more likely to hold after fitting the model. However, some data such as count data (e.g., weed counts, emergence counts, or panicle counts), which often follows non-normal distributions like the Poisson or negative binomial distributions are sometimes too not normally distributed for anova or t-test to mitigatre against their effect ont eh residuals.

To clarify, t-tests and ANOVA work by comparing the means of different groups based on the data at hand. For example, ANOVA compares group means by fitting a linear model to data with categorical predictors (e.g., comparing the means of different treatment groups). This linear model calculates predicted group means, and the residuals reflect the difference between the observed values and these predicted means.

However, there are certain situations where the process may not be enough to ensure that the residuals are normally distributed. When data is highly skewed or contains extreme values (i.e., long tails), or when the sample size within each group is small (typically less than 30, which is often the case in small-plot agricultural trials), assessing the normality of residuals becomes more difficult. Smaller sample sizes mean there’s less data to reliably detect patterns of non-normality, which can compromise the validity of the test results if the residuals are not approximately normally distributed or if normality cannot be clearly assessed.

Furthermore, while t-tests and ANOVA are effective when used in controlled experimental designs with carefully managed conditions, they are less suitable for on-farm experiments where environmental factors are often uncontrolled. Agricultural data can also be more complex, involving repeated measurements, hierarchical structures (e.g., multiple levels of observations such as fields, plots, and plants), and potential interactions between variables like treatment and environmental effects. These complexities cannot be fully captured by the standard t-test or ANOVA models. As a result, these methods may not adequately address the correlation between observations or the non-independence of data points within plots, which are common in real-world agricultural experiments.

Tests such as t-tests and ANOVA are commonly used to compare the means of different groups. These tests assume that the residuals (the differences between the observed values (raw data) and the model's fitted values) are normally distributed.

While the process of fitting a linear model (such as ANOVA or a t-test) reduces the impact of skewness or extreme values in the raw data by focusing on group-level patterns and generating predicted means. As a result, the residuals (the differences between the observed values and these predicted means) may become more normally distributed, even when the raw data is not. This smoothing effect helps to approximate normality in the residuals, making the assumptions of normality more likely to hold.

While the process of fitting a linear model with ANOVA or t-test can help reduce the impact of skewness or long tails in the raw data, leading to more normal residuals, the likelihood of non-normal residuals or uncertainty about their distribution increases when the data is highly skewed, has heavy tails, or when the sample size within each group is small (often less than 30, which is common in small-plot trials). Smaller sample sizes make it more difficult to assess the normality of residuals, as there may not be enough data to reliably detect patterns of non-normality. As a result, the validity of test results may be compromised if the residuals are not approximately normally distributed or if the assessment of normality is unclear.

Moreover, while t-tests and ANOVA are effective in controlled experimental designs with tightly managed conditions, they are less suitable for on-farm experiments where environmental factors often play a significant role and are challenging to control. These tests also do not account for more complex data structures, such as hierarchical data (e.g., multiple levels of observation like fields, plots, and plants) or interactions between variables (e.g., environmental and treatment effects). Furthermore, agricultural data often involves repeated measurements, correlations between observations, or non-independence within plots, which these tests cannot adequately address.

## **t-test**

The t-test compares the means of two groups to determine if the difference between them is statistically significant.

1.  **independent t-test** Compares means of two independent groups.
2.  **Paired t-test** Compares two measurements taken from the same subjects (before/after treatment, treatment/control).

**Output & Interpretation**:

-   **t-statistic**: Measures the difference between group means relative to the variability in the data. Larger values indicate stronger differences between the groupss
-   **Degrees of freedom (df)**: Represents the sample size adjusted for the number of estimated parameters. It influences the reliability of the test.
-   **P-value**: A p-value ≤ 0.05 indicates that the means differ significantly, suggesting the observed difference is unlikely due to chance. A p-value \> 0.05 suggests the means are not significantly different, and any observed variation is likely due to random fluctuations.

## **F-test (ANOVA)**

The F-test is used to compare the means of three or more groups, assessing whether there are statistically significant differences between them. It compares variance between groups to variance within groups to determine if the observed differences are meaningful.

1.  **One-way ANOVA**: Tests whether mean differences exist among multiple independent groups based on a single factor.
2.  **Two-way ANOVA**: Evaluates the effects of two factors simultaneously, considering their interactions, to determine how they influence the response variable.

**Outputs & Interpretation:**

-   **F-statistic**: Measures the ratio of variance between groups to variance within groups. A larger F-value suggests stronger evidence that group means are different.
-   **Degrees of freedom (df)**: Split into the model (number of groups minus one) and residuals (remaining data points not accounted for by the groups).
-   **P-value**:
    -   **p-value ≤ 0.05** suggests at least one group differs significantly, indicating that the observed differences are unlikely due to chance.
    -   **p-value \> 0.05** suggests that the differences across groups may be random and not due to a meaningful effect.

## Tests for Categorical or Ordinal Data:

Tests for categorical or ordinal data are used to examine relationships between variables where the response is either categorical (nominal) or ordinal.

**Categorical data**, also known as nominal data, consists of two or more categories without any intrinsic ordering. For example, binary responses such as disease presence or absence, or a list of two or more weed species or diseases present in each plot. In this case, the categories are simply labels with no meaningful numerical value or ranking attached.

Ordinal data is similar to categorical data, but the categories have a clear inherent order. However, unlike interval data, the distances between categories are not necessarily both standardised and uniform. For example, disease severity ratings or growth stage scales. A disease severity rating might rely on observational assessments whereby each plot is assigned a number based on the observers subjective assessment of whether the appropriate rating is 1 = no disease, 2 = mild, 3 = severe - in this example different observers may subjectively assign different ratings for the same plots and it is not necessarily expected that the difference between 1 "no disease" and 2"mild" is the same as thd difference betwen 2"mild and 3"severe so the data is neither standardised or uniform. The Zadoks’ Growth Stage Scale, on the other hand follows a consistent framework for describing plant development to help ensure that categories are definied or applied in a standardised way. However, this doesn't account for growth that sits between specified categories and the intervals between stages are not necessarily uniform; the amount of growth or time between stages can vary depending on factors like plant species, environmental conditions, or specific growing circumstances. For example, the difference between Z1 (main shoot leaf production) and Z2 (tiller production) may not be the same as the difference between Z3 (stem elongation) and Z4 (booting). therefore while Zadok's is a more standardised measure, and uniformity is improved, the Zadoks scale is considered ordinal in nature. While these stages allow us to rank the categories, calculating an "average" value is not meaningful due to the non-uniformity of the intervals.

**Ordinal data** is similar to categorical data, but the categories have a clear, inherent order. However, unlike interval data, the distances between categories are not uniform or standardised. For example, disease severity ratings or growth stage scales, such as the Zadoks Growth Stage Scale, assign numbers to categories (e.g., 1 = no disease, 2 = mild, 3 = severe) or stages of plant growth. Although these stages follow a logical sequence reflecting physical development, the intervals between them are not necessarily equal. For instance, the difference between Z1 (main shoot leaf production) and Z2 (tiller production) may not be the same as the difference between Z3 (stem elongation) and Z4 (booting). As a result, while ordinal scales allow us to rank categories, calculating an "average" value is not meaningful.

Note: Ordinal data often involves subjective or relative measures, and calculating means can be misleading because the intervals between categories may not be consistent.

Importance of Proper Analysis For both categorical and ordinal data, comparing group means is inappropriate. For example, computing the average disease severity across plots doesn’t make sense because the levels (e.g., mild vs. severe disease) are not equidistant. Instead, tests for categorical or ordinal data focus on comparing groups or categories using methods that examine the distribution of counts or the association between categories.

Chi-Squared Test The chi-squared test is used to analyse categorical data and determine whether observed frequencies differ significantly from expected values. There are two primary applications:

Goodness-of-Fit Test: Assesses whether the distribution of a single categorical variable matches an expected distribution. For example, it can evaluate whether seed germination rates follow predicted proportions across different environmental conditions. The expected distribution can be based on previous knowledge, literature, or predefined hypotheses. This doesn't always assume an even split of categories—it can accommodate expected distributions that reflect different proportions for each category.

Chi-Squared Test for Independence: Tests whether two categorical variables are associated. For example, it can determine if fertilizer type is related to crop growth categories.

Output & Interpretation:

Chi-square statistic: Measures the difference between observed and expected frequencies in categorical data. Higher values suggest stronger deviations from expected values.

Degrees of freedom (df): Calculated based on the number of categories minus constraints, determining the flexibility in comparing distributions.

P-value:

A p-value ≤ 0.05 indicates a significant difference or association, meaning the observed data does not match the expected values (Goodness-of-Fit) or that the variables are likely related (Independence Test).

A p-value \> 0.05 implies the observed differences or associations are likely due to random variation, rather than a meaningful effect.

z-test The z-test is often used to compare proportions in categorical data, especially when sample sizes are large and the population variances are known. It can test whether the observed proportions in different categories significantly differ from expected proportions. The expected proportions are typically based on known population values or theoretical assumptions, such as those derived from previous research or established models.

For example, in the context of a two-sample z-test, the expected proportion may come from existing literature, where a specific difference between two groups (e.g., 70% success rate for one treatment and 50% for another) has been well-established.

Output & Interpretation:

z-score: Measures how far a sample proportion deviates from the population proportion in standard deviations.

P-value:

A p-value ≤ 0.05 suggests a significant difference in proportions between groups.

A p-value \> 0.05 indicates no meaningful difference.

Tests for categorical or ordinal data are used to examine relationships between variables where the response is either categorical (nominal) or ordinal.

Categorical data (sometimes called nominal data) consists of two or more categories with no intrinsic ordering. For example, binary responses such as disease presence or absence, or a list or two or more weed species or diseases present in each plot. In these cases, the categories are simply labels with no ranking or meaningful numerical value attached.

Ordinal data is similar to categorical data, but the categories have a clear order. However, the distances between categories are not uniform or standardised. For instance, disease ratings or growth stage scales might assign numbers to levels (e.g., 1 = no disease, 2 = mild, 3 = severe), but the difference between the categories is not necessarily equal. For example, the difference in disease severity between "mild" (2) and "severe" (3) may not be the same as the difference between "none" (1) and "mild" (2). These scales allow us to rank the categories but do not make it meaningful to calculate the "average" value.

**Note:** Ordinal data often involves subjective or relative measures, and calculating means can be misleading because the intervals between categories may not be consistent.

For both types of data, comparing group means is not appropriate. For example, it would not make sense to compute the average disease presence across plots because the levels (e.g., mild vs. severe disease) are not equidistant. Tests for categorical or ordinal data, therefore, focus on comparing groups or categories using other methods, such as examining the distribution of counts or the association between different categories.

## **Chi-Squared Test**

The chi-squared test is used to analyse categorical data and determine whether observed frequencies differ significantly from expected values. There are two primary applications:

1.  **Goodness-of-Fit Test:** Assesses whether the distribution of a single categorical variable matches an expected distribution. For example, it can evaluate whether seed germination rates follow predicted proportions across different environmental conditions.
2.  **Chi-Squared Test for Independence:** Tests whether two categorical variables are associated. For example, it can determine if fertiliser type is related to crop growth categories.

**Output & Interpretation:**

-   **Chi-square statistic**: Measures the difference between observed and expected frequencies in categorical data. Higher values suggest stronger deviations from expected values.

-   **Degrees of freedom (df)**: Calculated based on the number of categories minus constraints, determining the flexibility in comparing distributions.

-   **P-value**:

    -   A p-value ≤ 0.05 indicates a significant difference or association, meaning the observed data does not match the expected values (Goodness-of-Fit) or that the variables are likely related (Independence Test).

    -   A p-value \> 0.05 implies the observed differences or associations are likely due to random variation, rather than a meaningful effect.

## **z-test**

The z-test is often used to compare proportions in categorical data, especially when sample sizes are large and the population variances are known. It can test whether the observed proportions in different categories significantly differ from expected proportions.

**Output & Interpretation**

-   **z-score:** Measures how far a sample proportion deviates from the population proportion in standard deviations.
-   **P-value**:
    -   A **p-value ≤ 0.05** suggests a significant difference in proportions between groups.

    -   A **p-value \> 0.05** indicates no meaningful difference.

## Model-Based Methods for Complex Data:

Model-based methods are more advanced tests that require fitting statistical models to the data. These tests are especially useful for analysing complex relationships, including hierarchical structures and interactions. They are also effective when dealing with non-normal data distributions or real-world variability, such as in agricultural trials where environmental influences are at play.

## **Wald test**

The Wald test assesses individual model parameters to determine whether specific predictors significantly influence the response variable. It is suitable for both binary and continuous response variables.

**Output & Interpretation:**

-   **Chi-square statistic**: Evaluates whether model coefficients differ significantly from sero. Larger values suggest greater evidence against the null hypothesis.

-   **Degrees of freedom (df)**: Represents the number of parameters being tested.

-   **P-value**:

    -   A **p-value ≤ 0.05** suggests a predictor significantly influences the response variable.

    -   A **p-value \> 0.05** indicates no meaningful impact.

## **Likelihood Ratio Test**

The Likelihood Ratio Test compares two nested models to determine whether adding predictors improves the model’s explanatory power. This test is often more reliable than the Wald test when sample sizes are small or when model complexity is high.

**Output & Interpretation:**

-   **Likelihood ratio statistic**: Compares how well two models fit the data. Larger values indicate better improvements in model fit with the added predictors.

-   **Degrees of freedom (df)**: Reflects the difference in complexity between the two models.

-   **P-value**:

    -   **p-value ≤ 0.05** suggests adding the predictor significantly improves the model’s performance.

    -   **p-value \> 0.05** indicates that removing the predictor does not weaken the model, meaning it may not be necessary.
